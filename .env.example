# Copy to .env.local (recommended for Next.js) or .env and adjust as needed
#   cp .env.example .env.local

# --- Database ---
# Default: SQLite in prisma/dev.db. You can also point to Postgres/MySQL if you change the Prisma provider.
# Note: the app normalizes relative SQLite file: URLs at runtime.
DATABASE_URL="file:./prisma/dev.db"

# --- LLM provider ---
# Values:
# - ollama (default): uses OLLAMA_* vars
# - openai-compat: uses OPENAI_COMPAT_* vars (OpenAI-like server, e.g. vLLM)
LLM_PROVIDER="ollama"

# --- Ollama (local LLM) ---
OLLAMA_BASE_URL="http://127.0.0.1:11434"
OLLAMA_MODEL="qwen2.5:7b-instruct"

# --- OpenAI-compatible (optional) ---
# Used only when LLM_PROVIDER=openai-compat.
# The app accepts either http://host:8000 or http://host:8000/v1
OPENAI_COMPAT_BASE_URL="http://127.0.0.1:8000"

# Required when LLM_PROVIDER=openai-compat
OPENAI_COMPAT_MODEL="Qwen/Qwen2.5-7B-Instruct"

# Optional: only if your server requires auth
# OPENAI_COMPAT_API_KEY=""
